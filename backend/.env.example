# ==========================================
# AI Interview Coach - Environment Variables
# ==========================================

# ENVIRONMENT CONFIGURATION
# Available environments: development, staging, production
NODE_ENV=development

# SERVER CONFIGURATION
# Port for the backend server
PORT=3000
# Host to bind the server to (0.0.0.0 for all interfaces, localhost for local only)
HOST=localhost
# Server timeout in milliseconds
SERVER_TIMEOUT=30000
# Maximum request body size
BODY_LIMIT=50kb

# API CONFIGURATION
# Base URL for the API (used by frontend and in responses)
API_BASE_URL=http://localhost:3000
# API version
API_VERSION=v1
# API timeout in milliseconds
API_TIMEOUT=30000

# AI SERVICE CONFIGURATION (REQUIRED)
# OpenRouter API key - GET THIS FROM https://openrouter.ai/
OPENROUTER_API_KEY=your_openrouter_api_key_here
# AI provider (openrouter, openai, anthropic)
AI_PROVIDER=openrouter
# OpenRouter base URL
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
# Default AI model to use
DEFAULT_AI_MODEL=qwen/qwen3-30b-a3b:free
# AI request timeout in milliseconds
AI_TIMEOUT=90000
# Maximum AI request retries
AI_MAX_RETRIES=2

# DATABASE CONFIGURATION
# Database type (sqlite, postgresql, mysql)
DB_TYPE=sqlite
# Database path (for SQLite) or connection string (for PostgreSQL/MySQL)
DB_PATH=./database/analytics.db
# Database connection timeout in milliseconds
DB_CONNECTION_TIMEOUT=5000
# Maximum database connections
DB_MAX_CONNECTIONS=10

# SECURITY CONFIGURATION
# Comma-separated list of allowed CORS origins
CORS_ORIGINS=http://localhost:3000,http://localhost:8080,http://127.0.0.1:3000,http://127.0.0.1:8080
# General rate limiting window in milliseconds (15 minutes default)
RATE_LIMIT_WINDOW=900000
# Maximum requests per rate limit window
RATE_LIMIT_MAX=100
# AI-specific rate limiting window in milliseconds (1 minute default)
AI_RATE_LIMIT_WINDOW=60000
# Maximum AI requests per rate limit window
AI_RATE_LIMIT_MAX=5
# Enable Helmet security headers (true/false)
ENABLE_HELMET=true
# Trust proxy headers (true/false) - enable if behind reverse proxy
TRUST_PROXY=false

# FRONTEND CONFIGURATION
# API URL that the frontend should use (can be different from API_BASE_URL)
FRONTEND_API_URL=http://localhost:3000
# Enable frontend analytics (true/false)
FRONTEND_ANALYTICS_ENABLED=true
# Enable frontend debug mode (true/false)
FRONTEND_DEBUG_MODE=false

# ANALYTICS CONFIGURATION
# Enable analytics collection (true/false)
ANALYTICS_ENABLED=true
# Admin password for analytics dashboard
ANALYTICS_ADMIN_PASSWORD=admin123
# Data retention period in days
ANALYTICS_RETENTION_DAYS=90
# Batch size for analytics processing
ANALYTICS_BATCH_SIZE=100

# LOGGING CONFIGURATION
# Log level (debug, info, warn, error)
LOG_LEVEL=info
# Enable file logging (true/false)
ENABLE_FILE_LOGGING=false
# Log file directory
LOG_PATH=./logs
# Maximum number of log files to keep
MAX_LOG_FILES=5
# Maximum size of each log file
MAX_LOG_SIZE=10MB

# APPLICATION METADATA
# Application name
APP_NAME=AI Interview Coach
# Application description
APP_DESCRIPTION=Smart interview preparation platform
# Application author
APP_AUTHOR=AI Interview Coach Team
# Application homepage URL
APP_HOMEPAGE=https://ai-interview-coach.com

# HTTP REFERER (for OpenRouter API)
# Your application URL for API attribution
HTTP_REFERER=http://localhost:3000

# ==========================================
# ENVIRONMENT-SPECIFIC EXAMPLES
# ==========================================

# DEVELOPMENT ENVIRONMENT EXAMPLE:
# NODE_ENV=development
# PORT=3000
# API_BASE_URL=http://localhost:3000
# FRONTEND_API_URL=http://localhost:3000
# CORS_ORIGINS=http://localhost:3000,http://localhost:8080,http://127.0.0.1:5500
# ANALYTICS_ADMIN_PASSWORD=dev123
# LOG_LEVEL=debug
# FRONTEND_DEBUG_MODE=true

# STAGING ENVIRONMENT EXAMPLE:
# NODE_ENV=staging
# PORT=3000
# API_BASE_URL=https://api-staging.ai-interview-coach.com
# FRONTEND_API_URL=https://api-staging.ai-interview-coach.com
# CORS_ORIGINS=https://staging.ai-interview-coach.com
# ANALYTICS_ADMIN_PASSWORD=staging_secure_password_here
# LOG_LEVEL=debug
# ENABLE_FILE_LOGGING=true
# TRUST_PROXY=true

# PRODUCTION ENVIRONMENT EXAMPLE:
# NODE_ENV=production
# PORT=3000
# API_BASE_URL=https://api.ai-interview-coach.com
# FRONTEND_API_URL=https://api.ai-interview-coach.com
# CORS_ORIGINS=https://ai-interview-coach.com,https://www.ai-interview-coach.com
# ANALYTICS_ADMIN_PASSWORD=super_secure_production_password_here
# LOG_LEVEL=info
# ENABLE_FILE_LOGGING=true
# LOG_PATH=/var/log/ai-interview-coach
# TRUST_PROXY=true
# DB_PATH=/var/lib/ai-interview-coach/analytics.db

# ==========================================
# OPTIONAL ADVANCED CONFIGURATION
# ==========================================

# BACKUP CONFIGURATION (Production)
# BACKUP_PATH=/var/backups/ai-interview-coach
# BACKUP_RETENTION_DAYS=30

# MONITORING CONFIGURATION (Production)
# ENABLE_METRICS=true
# METRICS_ENDPOINT=/metrics
# HEALTH_ENDPOINT=/health

# PERFORMANCE CONFIGURATION
# ENABLE_COMPRESSION=true
# ENABLE_CACHING=true
# CACHE_TTL=300
# MAX_CONCURRENT_REQUESTS=1000

# DEPLOYMENT CONFIGURATION
# AUTO_DEPLOY_BRANCH=main
# HEALTH_CHECK_TIMEOUT=30000
# ROLLBACK_ON_FAILURE=true

# ==========================================
# DOCKER CONFIGURATION
# ==========================================

# When running in Docker, use these settings:
# HOST=0.0.0.0
# DB_PATH=/app/data/analytics.db
# LOG_PATH=/app/logs

# ==========================================
# CLOUD DEPLOYMENT EXAMPLES
# ==========================================

# HEROKU EXAMPLE:
# NODE_ENV=production
# PORT=${PORT}
# DATABASE_URL=${DATABASE_URL}
# OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
# API_BASE_URL=https://your-app-name.herokuapp.com
# CORS_ORIGINS=https://your-frontend-domain.com

# AWS/DIGITAL OCEAN EXAMPLE:
# NODE_ENV=production
# PORT=3000
# API_BASE_URL=https://your-domain.com
# DB_PATH=/var/lib/ai-interview-coach/analytics.db
# LOG_PATH=/var/log/ai-interview-coach
# TRUST_PROXY=true